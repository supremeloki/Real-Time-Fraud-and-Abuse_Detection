{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SnappTech Real-Time Fraud & Abuse Detection Demo\n",
    "\n",
    "This Jupyter Notebook provides an interactive demonstration of the Snapp Real-Time Fraud & Abuse Detection system. It covers data simulation, model inference, and basic interpretability.\n",
    "\n",
    "**Before running this notebook:**\n",
    "1.  Ensure your local environment is set up as per `docs/03_SNAPPTECH_DEMO_GUIDE.md`.\n",
    "2.  Run the data generators:\n",
    "    ```bash\n",
    "    python data_vault/fraud_pattern_simulator/generate_abuse_scenarios.py\n",
    "    python data_vault/graph_topology_data/generate_collusion_graph.py\n",
    "    ```\n",
    "3.  Run the batch feature processor:\n",
    "    ```bash\n",
    "    python src/feature_forge/batch_features.py\n",
    "    python src/feature_forge/graph_features.py\n",
    "    ```\n",
    "4.  Train the LightGBM model:\n",
    "    ```bash\n",
    "    python src/model_arsenal/train_lightgbm.py --env dev\n",
    "    ```\n",
    "5.  Start the FastAPI prediction engine and Kafka consumer in separate terminals:\n",
    "    ```bash\n",
    "    uvicorn src.prediction_engine.fraud_detection_api:app --host 0.0.0.0 --port 8000\n",
    "    python src/ingestion_stream/kafka_event_consumer.py --env dev\n",
    "    ```\n",
    "    *Note: The Kafka consumer `handle_incoming_event` placeholder currently only logs the event. For a full loop, it would need to push to a processing queue that feeds features to Redis for the API to pull.* \n",
    "    *For this demo, we will directly call the InferenceEngine for simplicity and immediate feedback, bypassing Kafka for the `predict` step, but acknowledging Kafka's role in the real system.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Notebook\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import json\n",
    "import time\n",
    "import pandas as pd\n",
    "from datetime import datetime, timedelta\n",
    "import numpy as np\n",
    "import uuid\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from pathlib import Path\n",
    "\n",
    "# Import local modules (adjust sys.path if needed for direct import)\n",
    "import sys\n",
    "project_root = Path('../').resolve()\n",
    "if str(project_root) not in sys.path:\n",
    "    sys.path.append(str(project_root))\n",
    "\n",
    "# Ensure we're in the correct working directory for imports\n",
    "import os\n",
    "os.chdir(project_root)\n",
    "\n",
    "from src.prediction_engine.inference_logic import InferenceEngine\n",
    "from src.interpretability_module.explanation_generator import ExplanationGenerator\n",
    "from src.utils.common_helpers import load_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'C:\\\\Users\\\\Notebook\\\\Desktop\\\\Snapp\\\\2. Real-Time Fraud & Abuse Detection\\\\conf\\\\environments\\\\dev.yaml'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mFileNotFoundError\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[2]\u001b[39m\u001b[32m, line 3\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# Initialize Inference Engine and Explanation Generator (for direct calls)\u001b[39;00m\n\u001b[32m      2\u001b[39m config_directory = project_root / \u001b[33m\"\u001b[39m\u001b[33mconf\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m3\u001b[39m inference_engine = \u001b[43mInferenceEngine\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconfig_directory\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43menv\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mdev\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m      4\u001b[39m explanation_generator = ExplanationGenerator(config_directory, env=\u001b[33m'\u001b[39m\u001b[33mdev\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m      6\u001b[39m \u001b[38;5;66;03m# Set model and background data for ExplanationGenerator\u001b[39;00m\n\u001b[32m      7\u001b[39m \u001b[38;5;66;03m# This requires knowing the features used by the LGBM model\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\Desktop\\Snapp\\2. Real-Time Fraud & Abuse Detection\\src\\prediction_engine\\inference_logic.py:23\u001b[39m, in \u001b[36mInferenceEngine.__init__\u001b[39m\u001b[34m(self, config_path, env)\u001b[39m\n\u001b[32m     22\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, config_path: Path, env: \u001b[38;5;28mstr\u001b[39m):\n\u001b[32m---> \u001b[39m\u001b[32m23\u001b[39m     \u001b[38;5;28mself\u001b[39m.config = \u001b[43mload_config\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconfig_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43menv\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     24\u001b[39m     \u001b[38;5;28mself\u001b[39m.logger = setup_logging(\u001b[33m\"\u001b[39m\u001b[33mInferenceEngine\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28mself\u001b[39m.config[\u001b[33m\"\u001b[39m\u001b[33menvironment\u001b[39m\u001b[33m\"\u001b[39m][\u001b[33m\"\u001b[39m\u001b[33mlog_level\u001b[39m\u001b[33m\"\u001b[39m])\n\u001b[32m     25\u001b[39m     \u001b[38;5;28mself\u001b[39m.env = env\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\Desktop\\Snapp\\2. Real-Time Fraud & Abuse Detection\\src\\utils\\common_helpers.py:9\u001b[39m, in \u001b[36mload_config\u001b[39m\u001b[34m(config_path, env)\u001b[39m\n\u001b[32m      8\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mload_config\u001b[39m(config_path: Path, env: \u001b[38;5;28mstr\u001b[39m = \u001b[33m\"\u001b[39m\u001b[33mdev\u001b[39m\u001b[33m\"\u001b[39m):\n\u001b[32m----> \u001b[39m\u001b[32m9\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mconfig_path\u001b[49m\u001b[43m \u001b[49m\u001b[43m/\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43menvironments\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m/\u001b[49m\u001b[43m \u001b[49m\u001b[33;43mf\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43menv\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[33;43m.yaml\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mr\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[32m     10\u001b[39m         env_config = yaml.safe_load(f)\n\u001b[32m     12\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(config_path / \u001b[33m\"\u001b[39m\u001b[33mfraud_model_params.yaml\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mr\u001b[39m\u001b[33m'\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m f:\n",
      "\u001b[31mFileNotFoundError\u001b[39m: [Errno 2] No such file or directory: 'C:\\\\Users\\\\Notebook\\\\Desktop\\\\Snapp\\\\2. Real-Time Fraud & Abuse Detection\\\\conf\\\\environments\\\\dev.yaml'"
     ]
    }
   ],
   "source": [
    "# Initialize Inference Engine and Explanation Generator (for direct calls)\n",
    "config_directory = project_root / \"conf\"\n",
    "inference_engine = InferenceEngine(config_directory, env='dev')\n",
    "explanation_generator = ExplanationGenerator(config_directory, env='dev')\n",
    "\n",
    "# Set model and background data for ExplanationGenerator\n",
    "# This requires knowing the features used by the LGBM model\n",
    "if inference_engine.lightgbm_model and hasattr(inference_engine.lightgbm_model, 'feature_name_'):\n",
    "    mock_events_df = pd.read_csv(project_root / \"data_vault\" / \"synthetic_fraud_events.csv\")\n",
    "    mock_events_df[\"event_timestamp\"] = pd.to_datetime(mock_events_df[\"event_timestamp\"])\n",
    "    mock_events_df['hour_of_day'] = mock_events_df['event_timestamp'].dt.hour\n",
    "    mock_events_df['day_of_week'] = mock_events_df['event_timestamp'].dt.dayofweek\n",
    "    mock_events_df['distance_per_duration'] = mock_events_df['distance_km'] / (mock_events_df['duration_min'].replace(0, 1e-6))\n",
    "    mock_events_df['fare_per_km'] = mock_events_df['fare_amount'] / (mock_events_df['distance_km'].replace(0, 1e-6))\n",
    "    \n",
    "    try:\n",
    "        user_batch_features = pd.read_csv(project_root / \"data_vault\" / \"batch_user_features.csv\")\n",
    "        driver_batch_features = pd.read_csv(project_root / \"data_vault\" / \"batch_driver_features.csv\")\n",
    "        mock_events_df = mock_events_df.merge(user_batch_features, on='user_id', how='left')\n",
    "        mock_events_df = mock_events_df.merge(driver_batch_features, on='driver_id', how='left')\n",
    "    except FileNotFoundError:\n",
    "        print(\"Batch feature files not found. Skipping merge for explanation generator.\")\n",
    "    mock_events_df = mock_events_df.fillna(0)\n",
    "\n",
    "    lgbm_feature_names = inference_engine.lightgbm_model.feature_name_ if hasattr(inference_engine.lightgbm_model, 'feature_name_') else []\n",
    "    background_data_for_shap = mock_events_df[lgbm_feature_names]\n",
    "    explanation_generator.set_model_and_features(inference_engine.lightgbm_model, lgbm_feature_names, background_data_for_shap)\n",
    "else:\n",
    "    print(\"LightGBM model not loaded or feature names not accessible for explanation generator.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Simulate and Predict a Single Event\n",
    "\n",
    "Let's create a synthetic event and send it to the local prediction API (or directly to the `InferenceEngine` for faster demo).\n",
    "\n",
    "We'll simulate two types of events: a normal ride and a potentially fraudulent one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "API_URL = \"http://localhost:8000/predict\"\n",
    "\n",
    "def create_synthetic_event(user_id, driver_id, event_type, is_fraud_scenario=False):\n",
    "    event = {\n",
    "        \"event_id\": str(uuid.uuid4()),\n",
    "        \"event_timestamp\": datetime.now().isoformat(),\n",
    "        \"event_type\": event_type,\n",
    "        \"user_id\": user_id,\n",
    "        \"driver_id\": driver_id,\n",
    "        \"ride_id\": str(uuid.uuid4())[:8],\n",
    "        \"start_location_lat\": 35.72 + np.random.normal(0, 0.01),\n",
    "        \"start_location_lon\": 51.42 + np.random.normal(0, 0.01),\n",
    "        \"end_location_lat\": 35.75 + np.random.normal(0, 0.01),\n",
    "        \"end_location_lon\": 51.45 + np.random.normal(0, 0.01),\n",
    "        \"payment_method\": \"credit_card\",\n",
    "        \"device_info\": \"android_12\",\n",
    "        \"ip_address\": f\"192.168.1.{np.random.randint(1, 255)}\"\n",
    "    }\n",
    "    \n",
    "    if is_fraud_scenario:\n",
    "        event[\"fare_amount\"] = np.random.uniform(20000, 30000) # Unusually low fare\n",
    "        event[\"distance_km\"] = np.random.uniform(0.5, 2) # Very short distance\n",
    "        event[\"duration_min\"] = np.random.uniform(2, 5) # Very short duration\n",
    "        event[\"promo_code_used\"] = \"FAKE_PROMO\"\n",
    "        event[\"payment_method\"] = \"cash\" # Often preferred for fake rides\n",
    "    else:\n",
    "        event[\"fare_amount\"] = np.random.uniform(50000, 150000)\n",
    "        event[\"distance_km\"] = np.random.uniform(5, 25)\n",
    "        event[\"duration_min\"] = np.random.uniform(10, 45)\n",
    "        event[\"promo_code_used\"] = None\n",
    "        \n",
    "    return event"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Predicting Normal Event (via InferenceEngine direct call) ---\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'inference_engine' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[4]\u001b[39m\u001b[32m, line 4\u001b[39m\n\u001b[32m      2\u001b[39m normal_event = create_synthetic_event(\u001b[33m\"\u001b[39m\u001b[33muser_demo_1\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mdriver_demo_A\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mride_completed\u001b[39m\u001b[33m\"\u001b[39m, is_fraud_scenario=\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[32m      3\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33m--- Predicting Normal Event (via InferenceEngine direct call) ---\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m----> \u001b[39m\u001b[32m4\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[43minference_engine\u001b[49m.is_ready():\n\u001b[32m      5\u001b[39m     normal_prediction = inference_engine.run_inference(normal_event)\n\u001b[32m      6\u001b[39m     \u001b[38;5;28mprint\u001b[39m(json.dumps(normal_prediction, indent=\u001b[32m2\u001b[39m))\n",
      "\u001b[31mNameError\u001b[39m: name 'inference_engine' is not defined"
     ]
    }
   ],
   "source": [
    "# --- Normal Event --- \n",
    "normal_event = create_synthetic_event(\"user_demo_1\", \"driver_demo_A\", \"ride_completed\", is_fraud_scenario=False)\n",
    "print(\"--- Predicting Normal Event (via InferenceEngine direct call) ---\")\n",
    "if inference_engine.is_ready():\n",
    "    normal_prediction = inference_engine.run_inference(normal_event)\n",
    "    print(json.dumps(normal_prediction, indent=2))\n",
    "    \n",
    "    # Get Explanation for Normal Event\n",
    "    if 'explanation' in normal_prediction and explanation_generator.model is not None:\n",
    "        print(\"\\n--- Explanation for Normal Event ---\")\n",
    "        # Pass the extracted features from the inference engine for SHAP explanation\n",
    "        # In a real API call, explanation would be returned directly.\n",
    "        extracted_features = inference_engine._extract_features(normal_event)\n",
    "        explanation = explanation_generator.generate_shap_explanation(extracted_features)\n",
    "        print(json.dumps(explanation, indent=2))\n",
    "else:\n",
    "    print(\"Inference Engine not ready.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Predicting Fraudulent Event (via InferenceEngine direct call) ---\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'inference_engine' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[5]\u001b[39m\u001b[32m, line 4\u001b[39m\n\u001b[32m      2\u001b[39m fraud_event = create_synthetic_event(\u001b[33m\"\u001b[39m\u001b[33muser_high_risk\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mdriver_high_risk\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mride_completed\u001b[39m\u001b[33m\"\u001b[39m, is_fraud_scenario=\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[32m      3\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m--- Predicting Fraudulent Event (via InferenceEngine direct call) ---\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m----> \u001b[39m\u001b[32m4\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[43minference_engine\u001b[49m.is_ready():\n\u001b[32m      5\u001b[39m     fraud_prediction = inference_engine.run_inference(fraud_event)\n\u001b[32m      6\u001b[39m     \u001b[38;5;28mprint\u001b[39m(json.dumps(fraud_prediction, indent=\u001b[32m2\u001b[39m))\n",
      "\u001b[31mNameError\u001b[39m: name 'inference_engine' is not defined"
     ]
    }
   ],
   "source": [
    "# --- Fraudulent Event --- \n",
    "fraud_event = create_synthetic_event(\"user_high_risk\", \"driver_high_risk\", \"ride_completed\", is_fraud_scenario=True)\n",
    "print(\"\\n--- Predicting Fraudulent Event (via InferenceEngine direct call) ---\")\n",
    "if inference_engine.is_ready():\n",
    "    fraud_prediction = inference_engine.run_inference(fraud_event)\n",
    "    print(json.dumps(fraud_prediction, indent=2))\n",
    "\n",
    "    # Get Explanation for Fraudulent Event\n",
    "    if 'explanation' in fraud_prediction and explanation_generator.model is not None:\n",
    "        print(\"\\n--- Explanation for Fraudulent Event ---\")\n",
    "        extracted_features = inference_engine._extract_features(fraud_event)\n",
    "        explanation = explanation_generator.generate_shap_explanation(extracted_features)\n",
    "        print(json.dumps(explanation, indent=2))\n",
    "else:\n",
    "    print(\"Inference Engine not ready.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Real-time Monitoring Simulation\n",
    "\n",
    "Let's simulate a stream of events over time, including some fraudulent ones, and visualize the fraud scores.\n",
    "This helps to observe the system's behavior and detect patterns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_simulated_events = 50\n",
    "fraud_injection_rate = 0.2 # 20% of events will be fraudulent\n",
    "\n",
    "all_predictions = []\n",
    "\n",
    "print(f\"\\n--- Simulating {num_simulated_events} Events ---\")\n",
    "for i in range(num_simulated_events):\n",
    "    user = f\"user_{np.random.randint(1, 100)}\"\n",
    "    driver = f\"driver_{np.random.randint(1, 50)}\"\n",
    "    is_fraud = np.random.rand() < fraud_injection_rate\n",
    "    \n",
    "    current_event = create_synthetic_event(user, driver, \"ride_completed\", is_fraud_scenario=is_fraud)\n",
    "    \n",
    "    if inference_engine.is_ready():\n",
    "        prediction = inference_engine.run_inference(current_event)\n",
    "        prediction['timestamp'] = datetime.fromisoformat(current_event['event_timestamp'])\n",
    "        prediction['is_actual_fraud'] = is_fraud\n",
    "        all_predictions.append(prediction)\n",
    "    else:\n",
    "        print(\"Inference Engine not ready, skipping simulation.\")\n",
    "        break\n",
    "    \n",
    "    time.sleep(0.1) # Simulate real-time delay\n",
    "\n",
    "if all_predictions:\n",
    "    predictions_df = pd.DataFrame(all_predictions)\n",
    "    predictions_df['timestamp'] = pd.to_datetime(predictions_df['timestamp'])\n",
    "    predictions_df.set_index('timestamp', inplace=True)\n",
    "\n",
    "    plt.figure(figsize=(14, 7))\n",
    "    sns.lineplot(data=predictions_df, x=predictions_df.index, y='fraud_score', hue='is_actual_fraud', marker='o', alpha=0.7)\n",
    "    plt.axhline(y=inference_engine.config[\"thresholds\"][\"action_triggers\"][\"manual_review_queue_score\"], color='orange', linestyle='--', label='Manual Review Threshold')\n",
    "    plt.axhline(y=inference_engine.config[\"thresholds\"][\"action_triggers\"][\"auto_block_score\"], color='red', linestyle='--', label='Auto Block Threshold')\n",
    "    plt.title('Real-time Fraud Scores Over Time')\n",
    "    plt.xlabel('Time')\n",
    "    plt.ylabel('Fraud Score')\n",
    "    plt.ylim(-0.05, 1.05)\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    # Distribution of scores\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    sns.histplot(predictions_df, x='fraud_score', hue='is_actual_fraud', kde=True, bins=20)\n",
    "    plt.title('Distribution of Fraud Scores')\n",
    "    plt.xlabel('Fraud Score')\n",
    "    plt.ylabel('Count')\n",
    "    plt.axvline(x=inference_engine.config[\"thresholds\"][\"action_triggers\"][\"manual_review_queue_score\"], color='orange', linestyle='--', label='Manual Review Threshold')\n",
    "    plt.axvline(x=inference_engine.config[\"thresholds\"][\"action_triggers\"][\"auto_block_score\"], color='red', linestyle='--', label='Auto Block Threshold')\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Human Review Integration Simulation\n",
    "\n",
    "This section demonstrates how events might be added to a human review queue and subsequently processed with feedback."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.feedback_loop.human_review_integration import HumanReviewSystem\n",
    "\n",
    "review_system = HumanReviewSystem(config_directory, env='dev')\n",
    "\n",
    "print(\"--- Adding an event to human review queue ---\")\n",
    "high_score_event = create_synthetic_event(\"user_high_risk\", \"driver_high_risk\", \"ride_completed\", is_fraud_scenario=True)\n",
    "if inference_engine.is_ready():\n",
    "    prediction_for_review = inference_engine.run_inference(high_score_event)\n",
    "    if review_system.add_to_review_queue(prediction_for_review, high_score_event):\n",
    "        print(f\"Event {prediction_for_review['event_id']} added to queue.\")\n",
    "    else:\n",
    "        print(f\"Event {prediction_for_review['event_id']} did not meet review threshold (Score: {prediction_for_review['fraud_score']:.2f}).\")\n",
    "\n",
    "print(\"\\n--- Retrieving pending reviews ---\")\n",
    "pending_reviews = review_system.get_pending_reviews()\n",
    "if pending_reviews:\n",
    "    print(f\"Found {len(pending_reviews)} pending reviews.\")\n",
    "    for review in pending_reviews:\n",
    "        print(f\"  Event ID: {review['event_id']}, Predicted Score: {review['predicted_score']:.2f}, Suggested Action: {review['suggested_action']}\")\n",
    "    \n",
    "    # Simulate human decision\n",
    "    first_review_id = pending_reviews[0]['event_id']\n",
    "    print(f\"\\n--- Submitting human feedback for {first_review_id} (Confirmed Fraud) ---\")\n",
    "    review_system.submit_human_feedback(first_review_id, human_decision=True, reviewer_id=\"analyst_demo_1\", comments=\"Confirmed suspicious fare/distance for a new user.\")\n",
    "    \n",
    "    print(\"\\n--- Checking pending reviews after feedback ---\")\n",
    "    print(f\"Remaining pending reviews: {len(review_system.get_pending_reviews())}\")\n",
    "else:\n",
    "    print(\"No pending reviews to demonstrate.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
